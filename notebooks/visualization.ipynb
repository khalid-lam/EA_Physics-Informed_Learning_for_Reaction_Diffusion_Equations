{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dafbf21",
   "metadata": {},
   "source": [
    "# Visualization & Comparison Notebook\n",
    "## PINNs vs Linear Fourier Models — Poisson and Fisher–KPP/Logistic\n",
    "\n",
    "This notebook compares:\n",
    "- PDEs: **Poisson** (analytic reference) and **Fisher/Logistic stationary** (tutor-generated dataset)\n",
    "- Models: **MLP PINN** vs **Linear Fourier (positive frequencies)**\n",
    "- Objectives: **Residual loss** vs **Energy (variational) loss**\n",
    "- Loss variants: **with/without regularization**, **with/without data fitting term**\n",
    "\n",
    "We visualize:\n",
    "- Loss curves (total + components)\n",
    "- Predicted solution surfaces / contours\n",
    "- Error maps vs reference\n",
    "- Validation metrics tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ef37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD      : /workspaces/EA_Physics-Informed_Learning_for_Reaction_Diffusion_Equations/notebooks\n",
      "Repo root: /workspaces/EA_Physics-Informed_Learning_for_Reaction_Diffusion_Equations\n",
      "SRC path : /workspaces/EA_Physics-Informed_Learning_for_Reaction_Diffusion_Equations/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Start from the current working directory (where the notebook kernel runs)\n",
    "cwd = Path.cwd().resolve()\n",
    "\n",
    "# Find repo root by walking up until we find a \"src\" folder\n",
    "ROOT = cwd\n",
    "while not (ROOT / \"src\").exists() and ROOT != ROOT.parent:\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "SRC = ROOT / \"src\"\n",
    "sys.path.insert(0, str(SRC))\n",
    "\n",
    "print(\"CWD      :\", cwd)\n",
    "print(\"Repo root:\", ROOT)\n",
    "print(\"SRC path :\", SRC)\n",
    "\n",
    "\n",
    "from data_loader import load_torch_dataset, train_val_split\n",
    "from sampling import sample_uniform_interior, sample_uniform_boundary\n",
    "from equations import PoissonEquation, FisherKPPStationaryEquation\n",
    "from models import MLPModel, LinearFourierModel\n",
    "from solvers import train, evaluate_model\n",
    "from metrics import summarize_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc5ac05",
   "metadata": {},
   "source": [
    "## Global configuration\n",
    "\n",
    "We define:\n",
    "- device / dtype\n",
    "- common plotting utilities\n",
    "- helpers to run one experiment and collect results consistently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f017c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float32\n",
    "\n",
    "def make_grid_2d(n=80, low=0.0, high=1.0, device=device, dtype=dtype):\n",
    "    xs = torch.linspace(low, high, n, device=device, dtype=dtype)\n",
    "    X, Y = torch.meshgrid(xs, xs, indexing=\"ij\")\n",
    "    grid = torch.stack([X.reshape(-1), Y.reshape(-1)], dim=1)\n",
    "    return xs, grid\n",
    "\n",
    "def plot_history(history, title=\"Training history\"):\n",
    "    keys = [\"loss_total\", \"loss_pde\", \"loss_bc\", \"loss_data\", \"loss_reg\"]\n",
    "    plt.figure()\n",
    "    for k in keys:\n",
    "        if k in history and len(history[k]) > 0:\n",
    "            plt.plot(history[k], label=k)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_surface(xs, u_grid, title=\"u(x,y) surface\"):\n",
    "    # u_grid: (n*n, 1)\n",
    "    n = xs.numel()\n",
    "    U = u_grid.reshape(n, n).detach().cpu()\n",
    "    X, Y = torch.meshgrid(xs.cpu(), xs.cpu(), indexing=\"ij\")\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    ax.plot_surface(X.numpy(), Y.numpy(), U.numpy())\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_contour(xs, u_grid, title=\"u(x,y) contour\"):\n",
    "    n = xs.numel()\n",
    "    U = u_grid.reshape(n, n).detach().cpu()\n",
    "    X, Y = torch.meshgrid(xs.cpu(), xs.cpu(), indexing=\"ij\")\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.contourf(X.numpy(), Y.numpy(), U.numpy(), levels=40)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_error(xs, u_pred, u_true, title=\"|error|\"):\n",
    "    err = (u_pred - u_true).abs()\n",
    "    plot_contour(xs, err, title=title)\n",
    "\n",
    "def print_metrics(u_pred, u_true, title=\"Metrics\"):\n",
    "    m = summarize_errors(u_pred, u_true)\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for k,v in m.items():\n",
    "        print(f\"{k:>10s}: {v:.6e}\")\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae302b",
   "metadata": {},
   "source": [
    "## Unified experiment runner\n",
    "\n",
    "We create a helper to run a single training configuration:\n",
    "- equation object\n",
    "- model (MLP vs Fourier)\n",
    "- loss mode (residual vs energy)\n",
    "- weights (PDE / BC / data / reg)\n",
    "- collocation points\n",
    "- returns history + predictions on a grid + metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc9e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    *,\n",
    "    name: str,\n",
    "    equation,\n",
    "    model,\n",
    "    x_interior,\n",
    "    x_boundary=None,\n",
    "    u_boundary=None,\n",
    "    # supervised term:\n",
    "    x_data=None,\n",
    "    u_data=None,\n",
    "    # loss selection:\n",
    "    use_energy: bool = False,\n",
    "    # weights:\n",
    "    w_pde: float = 1.0,\n",
    "    w_bc: float = 0.0,\n",
    "    w_data: float = 0.0,\n",
    "    w_reg: float = 0.0,\n",
    "    # optimizer:\n",
    "    lr: float = 1e-3,\n",
    "    steps: int = 2000,\n",
    "    print_every: int = 200,\n",
    "    # evaluation grid:\n",
    "    grid_n: int = 80,\n",
    "    grid_low: float = 0.0,\n",
    "    grid_high: float = 1.0,\n",
    "    u_true_fn=None,      # callable for analytic reference on grid\n",
    "    u_true_data=None,    # tensor reference (val set)\n",
    "):\n",
    "    # NOTE: assumes your train() already supports data/reg weights if you added them.\n",
    "    # If not, it will still run with PDE/BC only.\n",
    "    history = train(\n",
    "        model,\n",
    "        equation,\n",
    "        x_interior,\n",
    "        x_boundary=x_boundary,\n",
    "        u_boundary=u_boundary,\n",
    "        x_data=x_data,\n",
    "        u_data=u_data,\n",
    "        use_energy=use_energy,\n",
    "        w_pde=w_pde,\n",
    "        w_bc=w_bc,\n",
    "        w_data=w_data,\n",
    "        w_reg=w_reg,\n",
    "        lr=lr,\n",
    "        steps=steps,\n",
    "        print_every=print_every,\n",
    "    )\n",
    "\n",
    "    xs, grid = make_grid_2d(n=grid_n, low=grid_low, high=grid_high)\n",
    "    with torch.no_grad():\n",
    "        u_pred_grid = model(grid).detach()\n",
    "\n",
    "    out = {\"name\": name, \"history\": history, \"xs\": xs, \"grid\": grid, \"u_pred_grid\": u_pred_grid}\n",
    "\n",
    "    if u_true_fn is not None:\n",
    "        with torch.no_grad():\n",
    "            u_true_grid = u_true_fn(grid).detach()\n",
    "        out[\"u_true_grid\"] = u_true_grid\n",
    "        out[\"metrics_grid\"] = summarize_errors(u_pred_grid, u_true_grid)\n",
    "\n",
    "    if (u_true_data is not None) and (x_data is not None):\n",
    "        with torch.no_grad():\n",
    "            u_pred_data = model(x_data).detach()\n",
    "        out[\"metrics_data\"] = summarize_errors(u_pred_data, u_true_data)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ead49",
   "metadata": {},
   "source": [
    "# Part A — Poisson equation (analytic reference)\n",
    "\n",
    "We use a known solution on the unit square:\n",
    "- Domain: [0,1]^2\n",
    "- Exact solution: u(x,y) = x^2 + y^2\n",
    "- Laplacian: Δu = 4\n",
    "For Poisson in the form: -Δu = f, we set f = -4.\n",
    "\n",
    "We use Dirichlet boundary values from the exact solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d3dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6000, 2]) torch.Size([1200, 2]) torch.Size([1200, 1])\n"
     ]
    }
   ],
   "source": [
    "def u_poisson_exact(x):\n",
    "    X = x[:, 0:1]\n",
    "    Y = x[:, 1:2]\n",
    "    return X**2 + Y**2\n",
    "\n",
    "f_poisson = lambda x: -4.0 * torch.ones(x.shape[0], 1, device=x.device, dtype=x.dtype)\n",
    "eq_poisson = PoissonEquation(f=f_poisson)\n",
    "\n",
    "# Collocation points\n",
    "n_in, n_b = 6000, 1200\n",
    "x_in = sample_uniform_interior(n_in, 2, device=device, dtype=dtype)\n",
    "x_b  = sample_uniform_boundary(n_b, 2, device=device, dtype=dtype)\n",
    "\n",
    "# Dirichlet BC from exact solution\n",
    "u_b = u_poisson_exact(x_b).detach()\n",
    "\n",
    "print(x_in.shape, x_b.shape, u_b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f1efa",
   "metadata": {},
   "source": [
    "## Poisson experiments\n",
    "\n",
    "We run:\n",
    "1) MLP + residual loss\n",
    "2) MLP + energy loss\n",
    "3) Fourier + residual loss\n",
    "4) Fourier + energy loss\n",
    "\n",
    "We also demonstrate \"with regularization\" vs \"no regularization\" by toggling `w_reg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2e045b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'x_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model_fn, use_energy, w_reg \u001b[38;5;129;01min\u001b[39;00m configs:\n\u001b[32m     19\u001b[39m     model = model_fn()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     res = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mequation\u001b[49m\u001b[43m=\u001b[49m\u001b[43meq_poisson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_interior\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_boundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mu_boundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mu_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_energy\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_energy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_pde\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_bc\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_data\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_reg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrid_n\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m90\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrid_low\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrid_high\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mu_true_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mu_poisson_exact\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     poisson_results.append(res)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone. Number of runs:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(poisson_results))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(name, equation, model, x_interior, x_boundary, u_boundary, x_data, u_data, use_energy, w_pde, w_bc, w_data, w_reg, lr, steps, print_every, grid_n, grid_low, grid_high, u_true_fn, u_true_data)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_experiment\u001b[39m(\n\u001b[32m      2\u001b[39m     *,\n\u001b[32m      3\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# NOTE: assumes your train() already supports data/reg weights if you added them.\u001b[39;00m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# If not, it will still run with PDE/BC only.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     history = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_interior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_boundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_boundary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mu_boundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mu_boundary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mu_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mu_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_energy\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_energy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_pde\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_pde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_bc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_bc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw_reg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     xs, grid = make_grid_2d(n=grid_n, low=grid_low, high=grid_high)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[31mTypeError\u001b[39m: train() got an unexpected keyword argument 'x_data'"
     ]
    }
   ],
   "source": [
    "poisson_results = []\n",
    "\n",
    "def make_mlp():\n",
    "    return MLPModel(input_dim=2, hidden_dim=64, num_hidden_layers=4, activation=\"tanh\").to(device)\n",
    "\n",
    "def make_fourier():\n",
    "    return LinearFourierModel(input_dim=2, max_frequency=8).to(device)\n",
    "\n",
    "configs = [\n",
    "    (\"MLP residual no-reg\",  make_mlp,   False, 0.0),\n",
    "    (\"MLP energy   no-reg\",  make_mlp,   True,  0.0),\n",
    "    (\"Fourier residual no-reg\", make_fourier, False, 0.0),\n",
    "    (\"Fourier energy   no-reg\", make_fourier, True,  0.0),\n",
    "    (\"MLP residual reg\",     make_mlp,   False, 1e-6),\n",
    "    (\"Fourier residual reg\", make_fourier, False, 1e-6),\n",
    "]\n",
    "\n",
    "for name, model_fn, use_energy, w_reg in configs:\n",
    "    model = model_fn()\n",
    "    res = run_experiment(\n",
    "        name=name,\n",
    "        equation=eq_poisson,\n",
    "        model=model,\n",
    "        x_interior=x_in,\n",
    "        x_boundary=x_b,\n",
    "        u_boundary=u_b,\n",
    "        use_energy=use_energy,\n",
    "        w_pde=1.0,\n",
    "        w_bc=10.0,\n",
    "        w_data=0.0,\n",
    "        w_reg=w_reg,\n",
    "        lr=1e-3,\n",
    "        steps=2000,\n",
    "        print_every=400,\n",
    "        grid_n=90,\n",
    "        grid_low=0.0,\n",
    "        grid_high=1.0,\n",
    "        u_true_fn=u_poisson_exact,\n",
    "    )\n",
    "    poisson_results.append(res)\n",
    "\n",
    "print(\"Done. Number of runs:\", len(poisson_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719aa60",
   "metadata": {},
   "source": [
    "## Poisson: loss curves\n",
    "\n",
    "We visualize the total loss and its components for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in poisson_results:\n",
    "    plot_history(r[\"history\"], title=f\"Poisson — {r['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6aa77",
   "metadata": {},
   "source": [
    "## Poisson: predicted solution vs exact solution\n",
    "\n",
    "We plot:\n",
    "- predicted u(x,y)\n",
    "- exact u(x,y)\n",
    "- absolute error map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in poisson_results:\n",
    "    xs = r[\"xs\"]\n",
    "    u_pred = r[\"u_pred_grid\"]\n",
    "    u_true = r[\"u_true_grid\"]\n",
    "\n",
    "    plot_contour(xs, u_pred, title=f\"Poisson — {r['name']} — u_pred\")\n",
    "    plot_contour(xs, u_true, title=f\"Poisson — exact u\")\n",
    "    plot_error(xs, u_pred, u_true, title=f\"Poisson — {r['name']} — |u_pred-u_true|\")\n",
    "    print_metrics(u_pred, u_true, title=f\"Poisson — {r['name']} — grid metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8286b65",
   "metadata": {},
   "source": [
    "# Part B — Fisher–KPP / Logistic stationary equation (tutor dataset)\n",
    "\n",
    "We load the dataset generated externally (finite differences + Newton).\n",
    "\n",
    "Important:\n",
    "- The dataset coordinates may be in [-0.5, 0.5) and are normalized to [0,1]^2 by the loader.\n",
    "- The underlying numerical solver was periodic (torus).\n",
    "  Dirichlet BCs may not be physically consistent, so we typically:\n",
    "  - rely on PDE residual + data term,\n",
    "  - optionally add regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = str(ROOT / \"data\" / \"logistic_mu0.100_sx50_sy50_coef2.667.pt\")\n",
    "\n",
    "ds, info = load_torch_dataset(data_path, normalize_to_unit=True)\n",
    "ds = type(ds)(x=ds.x.to(device=device, dtype=dtype), u=ds.u.to(device=device, dtype=dtype))\n",
    "\n",
    "train_ds, val_ds = train_val_split(ds, val_ratio=0.2, shuffle=True, seed=0)\n",
    "\n",
    "print(\"=== Dataset info ===\")\n",
    "print(\"Path:\", data_path)\n",
    "print(\"Normalized:\", info[\"normalized\"])\n",
    "print(\"Train:\", train_ds.x.shape, train_ds.u.shape)\n",
    "print(\"Val  :\", val_ds.x.shape, val_ds.u.shape)\n",
    "print(\"x range:\", train_ds.x.min().item(), train_ds.x.max().item())\n",
    "print(\"u range:\", train_ds.u.min().item(), train_ds.u.max().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064e5d2",
   "metadata": {},
   "source": [
    "## Fisher–KPP stationary PDE\n",
    "\n",
    "We set (example) parameters:\n",
    "- D (diffusion)\n",
    "- r (reaction rate)\n",
    "\n",
    "We train by mixing:\n",
    "- PDE term (residual or energy)\n",
    "- data term (fit u(x) on training set)\n",
    "- optional regularization\n",
    "\n",
    "We evaluate on:\n",
    "- validation set (same grid points, supervised)\n",
    "- and optionally on a dense [0,1]^2 grid for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f203dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_fisher = FisherKPPStationaryEquation(D=1.0, r=1.0)\n",
    "\n",
    "# Collocation points (domain [0,1]^2 after normalization)\n",
    "n_in, n_b = 8000, 0\n",
    "x_in = sample_uniform_interior(n_in, 2, device=device, dtype=dtype)\n",
    "\n",
    "# No BC for torus dataset by default\n",
    "x_b = None\n",
    "u_b = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f27cb",
   "metadata": {},
   "source": [
    "## Fisher experiments\n",
    "\n",
    "We compare:\n",
    "- MLP vs Fourier\n",
    "- residual vs energy\n",
    "- with/without regularization\n",
    "- with/without data fitting term\n",
    "\n",
    "In practice, the tutor dataset already represents a numerical solution, so the **data term is essential** to compare model expressivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_results = []\n",
    "\n",
    "configs = [\n",
    "    # name, model_fn, use_energy, w_data, w_reg\n",
    "    (\"MLP residual + data\",          make_mlp,    False, 1.0,  0.0),\n",
    "    (\"MLP residual + data + reg\",    make_mlp,    False, 1.0,  1e-6),\n",
    "    (\"MLP energy   + data\",          make_mlp,    True,  1.0,  0.0),\n",
    "    (\"Fourier residual + data\",      make_fourier,False, 1.0,  0.0),\n",
    "    (\"Fourier residual + data + reg\",make_fourier,False, 1.0,  1e-6),\n",
    "    (\"Fourier energy   + data\",      make_fourier,True,  1.0,  0.0),\n",
    "    (\"MLP residual PDE-only\",        make_mlp,    False, 0.0,  0.0),\n",
    "    (\"Fourier residual PDE-only\",    make_fourier,False, 0.0,  0.0),\n",
    "]\n",
    "\n",
    "for name, model_fn, use_energy, w_data, w_reg in configs:\n",
    "    model = model_fn()\n",
    "    res = run_experiment(\n",
    "        name=name,\n",
    "        equation=eq_fisher,\n",
    "        model=model,\n",
    "        x_interior=x_in,\n",
    "        x_boundary=x_b,\n",
    "        u_boundary=u_b,\n",
    "        x_data=train_ds.x,\n",
    "        u_data=train_ds.u,\n",
    "        use_energy=use_energy,\n",
    "        w_pde=1.0,\n",
    "        w_bc=0.0,\n",
    "        w_data=w_data,\n",
    "        w_reg=w_reg,\n",
    "        lr=1e-3,\n",
    "        steps=2500,\n",
    "        print_every=500,\n",
    "        grid_n=90,\n",
    "        grid_low=0.0,\n",
    "        grid_high=1.0,\n",
    "        u_true_fn=None,        # no analytic truth here\n",
    "    )\n",
    "    fisher_results.append(res)\n",
    "\n",
    "print(\"Done. Number of runs:\", len(fisher_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745e5c1",
   "metadata": {},
   "source": [
    "## Fisher: loss curves\n",
    "\n",
    "We plot losses for each configuration.\n",
    "Pay attention to:\n",
    "- stability of training\n",
    "- how data term dominates vs PDE term\n",
    "- effect of regularization (smoother training, sometimes better generalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in fisher_results:\n",
    "    plot_history(r[\"history\"], title=f\"Fisher — {r['name']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46520b",
   "metadata": {},
   "source": [
    "## Fisher: visualize solutions\n",
    "\n",
    "Since we do not have an analytic solution here, we compare:\n",
    "- u_pred on a dense grid\n",
    "- u_true interpolated is not available (dataset is sparse grid), so we:\n",
    "  - evaluate metrics on the validation set\n",
    "  - and visualize u_pred on [0,1]^2\n",
    "\n",
    "(Optionally, you can reshape the original 50x50 dataset and plot it as reference.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f92dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Fisher validation metrics (on val set) ===\")\n",
    "\n",
    "for r in fisher_results:\n",
    "    model = r.get(\"model\", None)  # might not be stored; so we recompute by reusing r[\"u_pred_grid\"] only for viz\n",
    "    # We instead compute val metrics by re-evaluating:\n",
    "    # NOTE: We didn't store model in r. For metrics, easiest is re-run evaluate directly here if you store it.\n",
    "    # Minimal workaround: do metrics inside the run, or store model in result dict.\n",
    "    pass\n",
    "\n",
    "out[\"model\"] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af59c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in fisher_results:\n",
    "    model = r[\"model\"]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        u_val_pred = model(val_ds.x)\n",
    "    print_metrics(u_val_pred, val_ds.u, title=f\"Fisher — {r['name']} — val metrics\")\n",
    "\n",
    "    xs = r[\"xs\"]\n",
    "    u_pred_grid = r[\"u_pred_grid\"]\n",
    "    plot_contour(xs, u_pred_grid, title=f\"Fisher — {r['name']} — u_pred (grid)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549b00a",
   "metadata": {},
   "source": [
    "## Optional: visualize the raw tutor dataset (as a surface)\n",
    "\n",
    "If your dataset comes from a regular 50x50 grid, you can reshape it and plot it\n",
    "(after normalization of x, if needed).\n",
    "This helps compare visually u_pred vs u_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88008e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to reshape if dataset is a full grid\n",
    "N = ds.x.shape[0]\n",
    "side = int(N ** 0.5)\n",
    "\n",
    "if side * side == N:\n",
    "    # Sort by x then y to reshape consistently\n",
    "    xy = ds.x.detach().cpu()\n",
    "    u = ds.u.detach().cpu()\n",
    "\n",
    "    idx = torch.argsort(xy[:, 0] * 10000 + xy[:, 1])\n",
    "    xy_s = xy[idx]\n",
    "    u_s = u[idx]\n",
    "\n",
    "    # Build a structured grid\n",
    "    xs_unique = torch.unique(xy_s[:, 0]).sort().values\n",
    "    ys_unique = torch.unique(xy_s[:, 1]).sort().values\n",
    "\n",
    "    if xs_unique.numel() * ys_unique.numel() == N:\n",
    "        U = u_s.reshape(xs_unique.numel(), ys_unique.numel())\n",
    "        X, Y = torch.meshgrid(xs_unique, ys_unique, indexing=\"ij\")\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.contourf(X.numpy(), Y.numpy(), U.numpy(), levels=40)\n",
    "        plt.colorbar()\n",
    "        plt.title(\"Tutor dataset u(x,y) (reshaped)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Dataset is not a perfect structured grid after sorting.\")\n",
    "else:\n",
    "    print(\"Dataset size is not a perfect square; cannot reshape to 2D grid.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8844c",
   "metadata": {},
   "source": [
    "# Part C — Summary and comparison\n",
    "\n",
    "We summarize key metrics:\n",
    "- Poisson: grid metrics vs analytic truth\n",
    "- Fisher: validation metrics vs dataset reference\n",
    "We highlight best runs per PDE and per method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Poisson summary (grid metrics) ===\")\n",
    "for r in poisson_results:\n",
    "    m = r.get(\"metrics_grid\", None)\n",
    "    if m is None:\n",
    "        continue\n",
    "    print(f\"{r['name']:<28s}  mse={m['mse']:.3e}  rel_l2={m['rel_l2']:.3e}  linf={m['linf']:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Fisher summary (val metrics) ===\")\n",
    "fisher_summary = []\n",
    "for r in fisher_results:\n",
    "    model = r.get(\"model\", None)\n",
    "    if model is None:\n",
    "        continue\n",
    "    with torch.no_grad():\n",
    "        u_val_pred = model(val_ds.x)\n",
    "    m = summarize_errors(u_val_pred, val_ds.u)\n",
    "    fisher_summary.append((r[\"name\"], m))\n",
    "    print(f\"{r['name']:<30s}  mse={m['mse']:.3e}  rel_l2={m['rel_l2']:.3e}  linf={m['linf']:.3e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d855cc0",
   "metadata": {},
   "source": [
    "## Next steps / Improvements\n",
    "\n",
    "- Add explicit periodicity constraints for the torus dataset:\n",
    "  - enforce u(x=0,y) ≈ u(x=1,y) and same for y\n",
    "  - enforce matching gradients (optional)\n",
    "- Add automated logging to disk:\n",
    "  - save history + config + final metrics in a results/ folder\n",
    "- Add L-BFGS as optional optimizer for PINNs\n",
    "- Add a consistent experiment registry (JSON configs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
